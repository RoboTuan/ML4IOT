{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "To connect VSCode to a Colab jupyter notebook, open a notebook in Colab and do execute the following code:\n",
    "# Install jupyterlab and ngrok\n",
    "!pip install jupyterlab pyngrok -q\n",
    "\n",
    "# Run jupyterlab in background\n",
    "!nohup jupyter lab --ip=0.0.0.0 &\n",
    "\n",
    "# Make jupyterlab accessible via ngrok\n",
    "from pyngrok import ngrok\n",
    "print(ngrok.connect(8888))\n",
    "\n",
    "After that, the output shoud be something similar to: NgrokTunnel: \"http://<uri_for_remote>\". Copy the url (\"http://<uri_for_remote>\")\n",
    "and in the command Palette of VSCode type \">jupyter:Specify local or remote Jupyter server for connections\".\n",
    "Select \"Existing, Specify the URI of an existing server\" and enter the previously copied uri. After that reload VSCode (as suggested)\n",
    "and open a notebook. If you need to change runtime (cpu, tpu, gpu), repeat all the procedure.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Thu Nov 26 16:52:46 2020       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   33C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n|                               |                      |                 ERR! |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class WindowGenerator:\n",
    "    def __init__(self, input_width, label_options, mean, std):\n",
    "        self.input_width = input_width\n",
    "        self.label_options = label_options\n",
    "        self.mean = tf.reshape(tf.convert_to_tensor(mean), [1, 1, 2])\n",
    "        #print(self.mean)\n",
    "        self.std = tf.reshape(tf.convert_to_tensor(std), [1, 1, 2])\n",
    "\n",
    "    def split_window(self, features):\n",
    "        input_indeces = np.arange(self.input_width)\n",
    "        inputs = features[:, :-1, :]\n",
    "        #print(inputs)\n",
    "        #print(features)\n",
    "\n",
    "        if self.label_options < 2:\n",
    "            labels = features[:, -1, self.label_options]\n",
    "            labels = tf.expand_dims(labels, -1)\n",
    "            num_labels = 1\n",
    "        else:\n",
    "            labels = features[:, -1, :]\n",
    "            num_labels = 2\n",
    "\n",
    "        inputs.set_shape([None, self.input_width, 2])\n",
    "        labels.set_shape([None, num_labels])\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def normalize(self, features):\n",
    "        # Adding a small number to the std so that if it's 0 it the program won't crash\n",
    "        features = (features - self.mean) / (self.std + 1.e-6)\n",
    "\n",
    "        return features\n",
    "\n",
    "    def preprocess(self, features):\n",
    "        inputs, labels = self.split_window(features)\n",
    "        inputs = self.normalize(inputs)\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def make_dataset(self, data, train):\n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "                data=data,\n",
    "                targets=None,\n",
    "                sequence_length=self.input_width+1,\n",
    "                sequence_stride=1,\n",
    "                batch_size=32) \n",
    "        ds = ds.map(self.preprocess)\n",
    "        ds = ds.cache()\n",
    "        if train is True:\n",
    "            ds = ds.shuffle(100, reshuffle_each_iteration=True)\n",
    "\n",
    "        return ds\n",
    "\n",
    "\n",
    "# To return the separated value, store the ouptput of the evalueate methods, in 2 variables,\n",
    "# one for the loss and one for the error and this will give 2 separated value for the error:\n",
    "# loss, error = model.evaluate(...) and print it manually\n",
    "class thMAE(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='thMAE', **kwargs):\n",
    "        super(thMAE, self).__init__(name=name, **kwargs)\n",
    "        # We need 2 at least 2 sensors, one to store the MAE computed so far (on the batch)\n",
    "        # and another variable to store the nmber of batches computed so far, so we can average\n",
    "        # the final error across the total number of samples processed.\n",
    "        # I can also write shape=[2] instead of hape=(2, )\n",
    "        self.total = self.add_weight(name='total', initializer='zeros', shape=(2, ))\n",
    "        # Shape not needed becasue it's just a scalar value\n",
    "        self.count = self.add_weight(name='count', initializer='zeros')\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.count.assign(tf.zeros_like(self.count))\n",
    "        self.total.assign(tf.zeros_like(self.total))\n",
    "\n",
    "        return\n",
    "\n",
    "    # Set sample_weight=None if I don't need it\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        error = tf.abs(y_pred - y_true)\n",
    "        error = tf.reduce_mean(error, axis=0)\n",
    "        self.total.assign_add(error)\n",
    "        self.count.assign_add(1)\n",
    "\n",
    "        return\n",
    "\n",
    "    def result(self):\n",
    "        # Computes a safe divide which returns 0 if the y is zero.\n",
    "        result = tf.math.divide_no_nan(self.total, self.count)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "class SignalGenerator:\n",
    "    def __init__(self, labels, sampling_rate, frame_length, frame_step,\n",
    "        num_mel_bins=None, lower_frequency=None, upper_frequency=None,\n",
    "        num_coefficients=None, mfcc=False):\n",
    "        \n",
    "\n",
    "        self.labels = labels\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.frame_length = frame_length\n",
    "        self.frame_step = frame_step\n",
    "        self.num_mel_bins = num_mel_bins\n",
    "        self.lower_frequency = lower_frequency\n",
    "        self.upper_frequency = upper_frequency\n",
    "        self.num_coefficients = num_coefficients\n",
    "        num_spectorgram_bin = (frame_length)//2 + 1\n",
    "\n",
    "        if mfcc is True:\n",
    "            self.linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "                    self.num_mel_bins, num_spectorgram_bin, self.sampling_rate,\n",
    "                    self.lower_frequency, self.upper_frequency)\n",
    "            self.preprocess = self.preprocess_with_mfcc\n",
    "\n",
    "        else:\n",
    "            self.preprocess = self.preprocess_with_stft\n",
    "\n",
    "\n",
    "\n",
    "    def read(self, file_path):\n",
    "        parts = tf.strings.split(file_path, os.path.sep)\n",
    "        label = parts[-2]\n",
    "        label_id = tf.argmax(label == self.labels)\n",
    "        audio_binary = tf.io.read_file(file_path)\n",
    "        audio, _ = tf.audio.decode_wav(audio_binary)\n",
    "        audio = tf.squeeze(audio, axis=1)\n",
    "\n",
    "        return audio, label_id\n",
    "\n",
    "    def pad(self, audio):\n",
    "        zero_padding = tf.zeros([self.sampling_rate] - tf.shape(audio), dtype=tf.float32)\n",
    "        audio = tf.concat([audio, zero_padding], 0)\n",
    "        audio.set_shape([self.sampling_rate])\n",
    "\n",
    "        return audio\n",
    "\n",
    "    def get_spectrogram(self, audio):\n",
    "        stft = tf.signal.stft(audio, frame_length=self.frame_length,\n",
    "                    frame_step=self.frame_step, fft_length=self.frame_length)\n",
    "        spectrogram = tf.abs(stft)\n",
    "\n",
    "        return spectrogram\n",
    "\n",
    "    def get_mfccs(self, spectrogram):\n",
    "        mel_spectrogram = tf.tensordot(spectrogram, self.linear_to_mel_weight_matrix, 1)\n",
    "        log_mel_spectrogram = tf.math.log(mel_spectrogram + 1e-6)\n",
    "        mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrogram)\n",
    "        mfccs = mfccs[..., :self.num_coefficients]\n",
    "\n",
    "        return mfccs\n",
    "\n",
    "    def preprocess_with_stft(self, file_path):\n",
    "        audio, label = self.read(file_path)\n",
    "        audio = self.pad(audio)\n",
    "        spectrogram = self.get_spectrogram(audio)\n",
    "        spectrogram = tf.expand_dims(spectrogram, -1)\n",
    "        spectrogram = tf.image.resize(spectrogram, [32, 32])\n",
    "\n",
    "        return spectrogram, label\n",
    "    \n",
    "    def preprocess_with_mfcc(self, file_path):\n",
    "        audio, label = self.read(file_path)\n",
    "        audio = self.pad(audio)\n",
    "        spectrogram = self.get_spectrogram(audio)\n",
    "        mfccs = self.get_mfccs(spectrogram)\n",
    "        mfccs = tf.expand_dims(spectrogram, -1)\n",
    "\n",
    "        return mfccs, label\n",
    "\n",
    "    def make_dataset(self, files, train):\n",
    "        ds = tf.data.Dataset.from_tensor_slices(files)\n",
    "        ds = ds.map(self.preprocess, num_parallel_calls=4)\n",
    "        ds = ds.batch(32)\n",
    "        ds = ds.cache()\n",
    "\n",
    "        if train is True:\n",
    "            ds = ds.shuffle(100, reshuffle_each_iteration=True)\n",
    "\n",
    "        return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "False\n",
      "Fit model on training data\n",
      "Epoch 1/20\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.8128 - sparse_categorical_accuracy: 0.3216 - val_loss: 1.5255 - val_sparse_categorical_accuracy: 0.4313\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.4264 - sparse_categorical_accuracy: 0.4783 - val_loss: 1.3365 - val_sparse_categorical_accuracy: 0.4988\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.2328 - sparse_categorical_accuracy: 0.5317 - val_loss: 1.2451 - val_sparse_categorical_accuracy: 0.5175\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.1241 - sparse_categorical_accuracy: 0.5711 - val_loss: 1.1802 - val_sparse_categorical_accuracy: 0.5500\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.0247 - sparse_categorical_accuracy: 0.6136 - val_loss: 1.1109 - val_sparse_categorical_accuracy: 0.5900\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.9306 - sparse_categorical_accuracy: 0.6384 - val_loss: 1.1169 - val_sparse_categorical_accuracy: 0.5913\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.8629 - sparse_categorical_accuracy: 0.6659 - val_loss: 1.1106 - val_sparse_categorical_accuracy: 0.6012\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.7800 - sparse_categorical_accuracy: 0.7013 - val_loss: 1.1145 - val_sparse_categorical_accuracy: 0.6162\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.7393 - sparse_categorical_accuracy: 0.7173 - val_loss: 1.1916 - val_sparse_categorical_accuracy: 0.5850\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.6768 - sparse_categorical_accuracy: 0.7419 - val_loss: 1.2357 - val_sparse_categorical_accuracy: 0.6062\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5980 - sparse_categorical_accuracy: 0.7756 - val_loss: 1.2612 - val_sparse_categorical_accuracy: 0.6112\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5527 - sparse_categorical_accuracy: 0.7898 - val_loss: 1.2954 - val_sparse_categorical_accuracy: 0.5987\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5378 - sparse_categorical_accuracy: 0.7998 - val_loss: 1.3716 - val_sparse_categorical_accuracy: 0.6150\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4839 - sparse_categorical_accuracy: 0.8223 - val_loss: 1.4901 - val_sparse_categorical_accuracy: 0.6137\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4476 - sparse_categorical_accuracy: 0.8366 - val_loss: 1.3619 - val_sparse_categorical_accuracy: 0.6363\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4311 - sparse_categorical_accuracy: 0.8445 - val_loss: 1.3644 - val_sparse_categorical_accuracy: 0.6175\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3958 - sparse_categorical_accuracy: 0.8542 - val_loss: 1.4978 - val_sparse_categorical_accuracy: 0.6250\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3619 - sparse_categorical_accuracy: 0.8727 - val_loss: 1.4499 - val_sparse_categorical_accuracy: 0.6413\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3025 - sparse_categorical_accuracy: 0.8923 - val_loss: 1.7009 - val_sparse_categorical_accuracy: 0.6363\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3027 - sparse_categorical_accuracy: 0.8931 - val_loss: 1.7764 - val_sparse_categorical_accuracy: 0.5962\n",
      "Evaluate on test data\n",
      "25/25 - 1s - loss: 1.8647 - sparse_categorical_accuracy: 0.5850\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "first_dense (Dense)          (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "second_dense (Dense)         (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "third_dense (Dense)          (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 396,040\n",
      "Trainable params: 396,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#from utils import *\n",
    "import sys\n",
    "\n",
    "\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument('--model', type=str, default='CNN')\n",
    "#parser.add_argument('--mfcc', action='store_true')\n",
    "#args = parser.parse_args()\n",
    "\n",
    "MFCC = False\n",
    "MODEL = \"MLP\"\n",
    "print(MFCC)\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "zip_path = tf.keras.utils.get_file(\n",
    "         origin='http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip',\n",
    "              fname='mini_speech_commands.zip',\n",
    "     extract=True,\n",
    "     cache_dir='.',\n",
    "     cache_subdir='data',\n",
    " )\n",
    "\n",
    "data_dir = os.path.join('.', 'data', 'mini_speech_commands')\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')\n",
    "# Shuffle to have a normal distribution\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "n = len(filenames)\n",
    "\n",
    "train_file = filenames[:int(n*0.8)]\n",
    "val_files = filenames[int(n*0.8):int(n*0.9)]\n",
    "test_files = filenames[int(n*0.9):]\n",
    "\n",
    "LABELS = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "LABELS = LABELS[LABELS != \"README.md\"]\n",
    "\n",
    "# check the frequency\n",
    "# frequency = 16000\n",
    "# frame_length = 16\n",
    "# frame_step = 8\n",
    "\n",
    "STFT_OPTIONS = {'frame_length': 16, 'frame_step': 8, 'mfcc':False}\n",
    "MFCC_OPTIONS =  {'frame_length': 40, 'frame_step': 20, 'mfcc':True,\n",
    "                    'lower_frequency':20, 'upper_frequency':4000,\n",
    "                    'num_mel_bins':40, 'num_coefficients':10}\n",
    "\n",
    "\n",
    "if MFCC == True:\n",
    "    options = MFCC_OPTIONS\n",
    "    strides = [2,1]\n",
    "else:\n",
    "    options = STFT_OPTIONS\n",
    "    strides = [2,2]\n",
    "\n",
    "\n",
    "signal = SignalGenerator(LABELS, 16000, **options)\n",
    "train_ds = signal.make_dataset(train_file, True)\n",
    "val_ds = signal.make_dataset(val_files, False)\n",
    "test_ds = signal.make_dataset(test_files, False)\n",
    "\n",
    "\n",
    "# print(train_file)\n",
    "\n",
    "# ds = tf.data.Dataset.from_tensor_slices(train_file)\n",
    "# for element in ds:\n",
    "#     parts = tf.strings.split(element, os.path.sep)\n",
    "#     print(parts)\n",
    "#     label = parts[-2]\n",
    "#     print(label)\n",
    "#     label_id = tf.argmax(label == LABELS)\n",
    "#     print(label_id)\n",
    "#     audio_binary = tf.io.read_file(element)\n",
    "#     #print(audio_binary)\n",
    "#     audio, _ = tf.audio.decode_wav(audio_binary)\n",
    "#     print(audio)\n",
    "#     audio = tf.squeeze(audio, axis=1)\n",
    "#     print(audio)\n",
    "\n",
    "#     zero_padding = tf.zeros([16000] - tf.shape(audio), dtype=tf.float32)\n",
    "#     print(zero_padding)\n",
    "#     audio = tf.concat([audio, zero_padding], 0)\n",
    "#     print(audio)\n",
    "#     audio.set_shape([16000])\n",
    "#     print(audio)    \n",
    "#     break\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "if MODEL == \"MLP\":\n",
    "    model = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu', name='first_dense'),\n",
    "    keras.layers.Dense(256, activation='relu', name='second_dense'),\n",
    "    keras.layers.Dense(256, activation='relu', name='third_dense'),\n",
    "    keras.layers.Dense(8, name='classifier'),\n",
    "    ])\n",
    "\n",
    "elif MODEL == \"CNN\":\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv2D(filters=128, kernel_size=[3,3], strides=strides, use_bias=False, name='first_conv'),\n",
    "        keras.layers.BatchNormalization(momentum=0.1),\n",
    "        keras.layers.Activation('relu'),\n",
    "        keras.layers.Conv2D(filters=128, kernel_size=[3,3], strides=[1, 1], use_bias=False, name='second_conv'),\n",
    "        keras.layers.BatchNormalization(momentum=0.1),\n",
    "        keras.layers.Activation('relu'),\n",
    "        keras.layers.Conv2D(filters=128, kernel_size=[3,3], strides=[1, 1], use_bias=False, name='third_conv'),\n",
    "        keras.layers.BatchNormalization(momentum=0.1),\n",
    "        keras.layers.Activation('relu'),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.Dense(8, name='classifier')\n",
    "    ])\n",
    "\n",
    "elif MODEL == \"DS-CNN\":\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv2D(filters=256, kernel_size=[3, 3], strides=strides, use_bias=False),\n",
    "        keras.layers.BatchNormalization(momentum=0.1),\n",
    "        keras.layers.Activation('relu'),\n",
    "        keras.layers.DepthwiseConv2D(kernel_size=[3, 3], strides=[1, 1], use_bias=False),\n",
    "        keras.layers.Conv2D(filters=256, kernel_size=[1, 1], strides=[1, 1], use_bias=False),\n",
    "        keras.layers.BatchNormalization(momentum=0.1),\n",
    "        keras.layers.Activation('relu'),\n",
    "        keras.layers.DepthwiseConv2D(kernel_size=[3, 3], strides=[1, 1], use_bias=False),\n",
    "        keras.layers.Conv2D(filters=256, kernel_size=[1, 1], strides=[1, 1], use_bias=False),\n",
    "        keras.layers.BatchNormalization(momentum=0.1),\n",
    "        keras.layers.Activation('relu'),    \n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.Dense(8)\n",
    "    ])\n",
    "\n",
    "else:\n",
    "    print(\"Model not defined\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=[tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)],\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "metric = 'val_sparse_categorical_accuracy'\n",
    "\n",
    "checkpoint_filepath = './checkpoint/kws_{}_{}/weights'.format(MODEL, MFCC)\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_sparse_categorical_accuracy', # also metric is ok\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "print(\"Fit model on training data\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(val_ds),\n",
    "    callbacks=[model_checkpoint_callback]\n",
    ")\n",
    "\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(test_ds, verbose=2)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "save_model_dir = './models/kws_{}_{}'.format(MODEL, MFCC)\n",
    "if not os.path.exists(save_model_dir):\n",
    "    os.makedirs(save_model_dir)\n",
    "\n",
    "# for key in history.history:\n",
    "#     print(key)\n",
    "\n",
    "# for element in train_ds:\n",
    "#     print(element)\n",
    "#     break \n",
    "\n",
    "# y_true = [2, 1]\n",
    "# y_pred = [[0], [0]]\n",
    "# m = tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "# print(m)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}